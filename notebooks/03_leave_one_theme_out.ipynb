{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e9b97f5",
   "metadata": {},
   "source": [
    "# Leave-one-theme-out generalization (Style vs TF-IDF vs Combined)\n",
    "\n",
    "For each **Theme bucket** `T`, train on all other themes and test on `T`.\n",
    "\n",
    "Models:\n",
    "- **Style-only (no Theme):** Claim/Framing + CTA + Evidence (Link/URL evidence removed as in v6)\n",
    "- **TF-IDF** text baseline (URLs already stripped from text)\n",
    "- **Combined** stacked ensemble (same meta-features as v6)\n",
    "\n",
    "Report:\n",
    "- Per-theme macro-F1 bar chart.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f7ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    brier_score_loss,\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "def _resolve_upward(start: Path, rel: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        cand = p / rel\n",
    "        if cand.exists():\n",
    "            return cand\n",
    "    raise FileNotFoundError(f\"Could not resolve path upward: {rel}\")\n",
    "\n",
    "\n",
    "HERE = Path.cwd().resolve()\n",
    "DATA_PATH = _resolve_upward(\n",
    "    HERE,\n",
    "    Path(\"mbfc_channel_masked_logreg_fullpackage_v2_MBFC_C\") / \"MBFC \" / \"mega_samples_dedup_qwen_mbfc.csv\",\n",
    ")\n",
    "print({\"data_path\": str(DATA_PATH)})\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "if \"source\" not in df.columns:\n",
    "    df = df.rename(columns={df.columns[0]: \"source\"})\n",
    "\n",
    "# Match v6 preprocessing: strip URLs from message text.\n",
    "df[\"message\"] = (\n",
    "    df[\"message\"]\n",
    "    .astype(str)\n",
    "    .str.replace(r\"(https?://|http://|www\\.[^\\s]*|t\\.me/[^\\s]*)\", \" \", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "df = df[df[\"message\"] != \"\"].copy()\n",
    "\n",
    "# Keep only confident labels and rows with a domain.\n",
    "df = df.dropna(subset=[\"risk_label\", \"normalized_domain\"]).copy()\n",
    "df[\"y\"] = df[\"risk_label\"].astype(int)\n",
    "\n",
    "print(\n",
    "    {\n",
    "        \"rows\": int(len(df)),\n",
    "        \"unique_domains\": int(df[\"normalized_domain\"].nunique()),\n",
    "        \"pos_rate\": float(df[\"y\"].mean()),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "RESULTS_DIR = Path(\"mbfc_url_masked_logreg_leave_one_theme_out_results_v1\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "print({\"results_dir\": str(RESULTS_DIR.resolve())})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14025f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theme normalization (same buckets as v6)\n",
    "\n",
    "THEME_BUCKETS = [\n",
    "    \"Finance/Crypto\",\n",
    "    \"Public health & medicine\",\n",
    "    \"Politics\",\n",
    "    \"Lifestyle & well-being\",\n",
    "    \"Crime & public safety\",\n",
    "    \"Gaming/Gambling\",\n",
    "    \"News/Information\",\n",
    "    \"Sports\",\n",
    "    \"Technology\",\n",
    "    \"Conversation/Chat/Other\",\n",
    "    \"Other theme\",\n",
    "]\n",
    "\n",
    "\n",
    "def _norm_theme(raw: object) -> Optional[str]:\n",
    "    if not isinstance(raw, str):\n",
    "        return None\n",
    "    t = raw.strip()\n",
    "    if not t:\n",
    "        return None\n",
    "    t = t.replace(\"\\u2011\", \"-\").replace(\"\\u2013\", \"-\").replace(\"\\u2014\", \"-\")\n",
    "    tl = t.lower()\n",
    "\n",
    "    if t in THEME_BUCKETS:\n",
    "        return t\n",
    "\n",
    "    if any(\n",
    "        k in tl\n",
    "        for k in [\n",
    "            \"crypto\",\n",
    "            \"token\",\n",
    "            \"coin\",\n",
    "            \"airdrop\",\n",
    "            \"ido\",\n",
    "            \"staking\",\n",
    "            \"defi\",\n",
    "            \"exchange\",\n",
    "            \"market\",\n",
    "            \"finance\",\n",
    "            \"econom\",\n",
    "        ]\n",
    "    ):\n",
    "        return \"Finance/Crypto\"\n",
    "\n",
    "    if any(\n",
    "        k in tl\n",
    "        for k in [\n",
    "            \"health\",\n",
    "            \"covid\",\n",
    "            \"vaccine\",\n",
    "            \"vaccination\",\n",
    "            \"medicine\",\n",
    "            \"medical\",\n",
    "            \"clinical\",\n",
    "            \"disease\",\n",
    "            \"pandemic\",\n",
    "            \"public health\",\n",
    "            \"hospital\",\n",
    "        ]\n",
    "    ):\n",
    "        return \"Public health & medicine\"\n",
    "\n",
    "    if any(\n",
    "        k in tl\n",
    "        for k in [\n",
    "            \"politic\",\n",
    "            \"election\",\n",
    "            \"parliament\",\n",
    "            \"congress\",\n",
    "            \"senate\",\n",
    "            \"government\",\n",
    "            \"president\",\n",
    "            \"minister\",\n",
    "            \"policy\",\n",
    "            \"war\",\n",
    "            \"conflict\",\n",
    "            \"ukraine\",\n",
    "            \"russia\",\n",
    "        ]\n",
    "    ):\n",
    "        return \"Politics\"\n",
    "\n",
    "    if any(\n",
    "        k in tl\n",
    "        for k in [\n",
    "            \"crime\",\n",
    "            \"criminal\",\n",
    "            \"terror\",\n",
    "            \"shooting\",\n",
    "            \"police\",\n",
    "            \"public safety\",\n",
    "            \"fraud\",\n",
    "            \"scam\",\n",
    "        ]\n",
    "    ):\n",
    "        return \"Crime & public safety\"\n",
    "\n",
    "    if any(k in tl for k in [\"gaming\", \"gambling\", \"casino\", \"betting\", \"lottery\", \"poker\"]):\n",
    "        return \"Gaming/Gambling\"\n",
    "\n",
    "    if any(k in tl for k in [\"sport\", \"football\", \"soccer\", \"basketball\", \"tennis\", \"nba\", \"nfl\"]):\n",
    "        return \"Sports\"\n",
    "\n",
    "    if any(\n",
    "        k in tl\n",
    "        for k in [\n",
    "            \"technology\",\n",
    "            \"tech\",\n",
    "            \"software\",\n",
    "            \"app \",\n",
    "            \"platform\",\n",
    "            \"ai \",\n",
    "            \" a.i.\",\n",
    "            \"machine learning\",\n",
    "            \"blockchain\",\n",
    "            \"internet\",\n",
    "            \"social media\",\n",
    "            \"algorithm\",\n",
    "            \"science\",\n",
    "            \"research\",\n",
    "            \"study\",\n",
    "        ]\n",
    "    ):\n",
    "        return \"Technology\"\n",
    "\n",
    "    if any(\n",
    "        k in tl\n",
    "        for k in [\n",
    "            \"lifestyle\",\n",
    "            \"well-being\",\n",
    "            \"wellbeing\",\n",
    "            \"culture\",\n",
    "            \"entertainment\",\n",
    "            \"media\",\n",
    "            \"celebrity\",\n",
    "            \"social issues\",\n",
    "            \"society\",\n",
    "            \"family\",\n",
    "            \"community\",\n",
    "        ]\n",
    "    ):\n",
    "        return \"Lifestyle & well-being\"\n",
    "\n",
    "    if any(k in tl for k in [\"news\", \"headline\", \"breaking\", \"coverage\", \"roundup\", \"update\"]):\n",
    "        return \"News/Information\"\n",
    "\n",
    "    if any(k in tl for k in [\"comment\", \"conversation\", \"chat\", \"q&a\", \"ama\", \"ask me anything\"]):\n",
    "        return \"Conversation/Chat/Other\"\n",
    "\n",
    "    return \"Other theme\"\n",
    "\n",
    "\n",
    "df[\"theme_norm\"] = df[\"theme\"].apply(_norm_theme)\n",
    "df = df.dropna(subset=[\"theme_norm\"]).copy()\n",
    "print(df[\"theme_norm\"].value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63683e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style-only (no Theme) tag normalization (v6 behavior: Link/URL removed)\n",
    "\n",
    "DROP_LINK_URL_LABEL = True\n",
    "_LINK_URL_LABEL_NORM = \"link/url\"\n",
    "\n",
    "\n",
    "def tokenize_multi(value: object) -> List[str]:\n",
    "    if not isinstance(value, str):\n",
    "        return []\n",
    "    value = value.replace(\"+\", \",\")\n",
    "    parts = [part.strip() for part in value.split(\",\") if part.strip()]\n",
    "    if not DROP_LINK_URL_LABEL:\n",
    "        return parts\n",
    "    return [p for p in parts if \"\".join(p.lower().split()) != _LINK_URL_LABEL_NORM]\n",
    "\n",
    "\n",
    "CLAIM_BUCKETS = [\n",
    "    \"Verifiable factual statement\",\n",
    "    \"Rumour / unverified report\",\n",
    "    \"Announcement\",\n",
    "    \"Opinion / subjective statement\",\n",
    "    \"Misleading context / cherry-picking\",\n",
    "    \"Promotional hype / exaggerated profit guarantee\",\n",
    "    \"Emotional appeal / fear-mongering\",\n",
    "    \"Scarcity/FOMO tactic\",\n",
    "    \"Statistics\",\n",
    "    \"Other claim type\",\n",
    "    \"No substantive claim\",\n",
    "    \"Fake content\",\n",
    "    \"Speculative forecast / prediction\",\n",
    "    \"None / assertion only\",\n",
    "]\n",
    "\n",
    "CTA_BUCKETS = [\n",
    "    \"Visit external link / watch video\",\n",
    "    \"Engage/Ask questions\",\n",
    "    \"Join/Subscribe\",\n",
    "    \"Buy / invest / donate\",\n",
    "    \"Attend event / livestream\",\n",
    "    \"Share / repost / like\",\n",
    "    \"No CTA\",\n",
    "    \"Other CTA\",\n",
    "]\n",
    "\n",
    "EVID_BUCKETS = [\n",
    "    \"Link/URL\",\n",
    "    \"Statistics\",\n",
    "    \"Quotes/Testimony\",\n",
    "    \"Chart / price graph / TA diagram\",\n",
    "    \"Other (Evidence)\",\n",
    "    \"None / assertion only\",\n",
    "]\n",
    "\n",
    "\n",
    "def _norm_claim_labels(raw: object) -> List[str]:\n",
    "    labels = tokenize_multi(raw)\n",
    "    out: List[str] = []\n",
    "    for lbl in labels:\n",
    "        base = lbl.strip()\n",
    "        if not base:\n",
    "            continue\n",
    "        low = base.lower()\n",
    "        if base in CLAIM_BUCKETS:\n",
    "            out.append(base)\n",
    "            continue\n",
    "        if \"verifiable\" in low or \"factual\" in low:\n",
    "            out.append(\"Verifiable factual statement\")\n",
    "        elif \"rumour\" in low or \"unverified\" in low:\n",
    "            out.append(\"Rumour / unverified report\")\n",
    "        elif \"misleading context\" in low or \"cherry\" in low:\n",
    "            out.append(\"Misleading context / cherry-picking\")\n",
    "        elif \"promotional hype\" in low or \"exaggerated profit\" in low:\n",
    "            out.append(\"Promotional hype / exaggerated profit guarantee\")\n",
    "        elif \"emotional appeal\" in low or \"fear-mongering\" in low or \"fear mongering\" in low:\n",
    "            out.append(\"Emotional appeal / fear-mongering\")\n",
    "        elif \"scarcity\" in low or \"fomo\" in low:\n",
    "            out.append(\"Scarcity/FOMO tactic\")\n",
    "        elif \"statistic\" in low:\n",
    "            out.append(\"Statistics\")\n",
    "        elif \"fake content\" in low or \"fabricated\" in low:\n",
    "            out.append(\"Fake content\")\n",
    "        elif \"predict\" in low or \"forecast\" in low:\n",
    "            out.append(\"Speculative forecast / prediction\")\n",
    "        elif \"announcement\" in low:\n",
    "            out.append(\"Announcement\")\n",
    "        elif \"opinion\" in low or \"interpretive\" in low or \"analysis\" in low or \"review\" in low:\n",
    "            out.append(\"Opinion / subjective statement\")\n",
    "        elif \"none / assertion only\" in low or \"assertion only\" in low:\n",
    "            out.append(\"None / assertion only\")\n",
    "        else:\n",
    "            out.append(\"Other claim type\")\n",
    "    seen = set()\n",
    "    result: List[str] = []\n",
    "    for v in out:\n",
    "        if v not in seen:\n",
    "            seen.add(v)\n",
    "            result.append(v)\n",
    "    return result\n",
    "\n",
    "\n",
    "def _norm_cta_labels(raw: object) -> List[str]:\n",
    "    labels = tokenize_multi(raw)\n",
    "    out: List[str] = []\n",
    "    for lbl in labels:\n",
    "        base = lbl.strip()\n",
    "        if not base:\n",
    "            continue\n",
    "        low = base.lower()\n",
    "        if base in CTA_BUCKETS:\n",
    "            out.append(base)\n",
    "            continue\n",
    "        if base in {\"None\", \"No CTA\"} or \"no cta\" in low:\n",
    "            out.append(\"No CTA\")\n",
    "        elif \"engage\" in low or \"ask\" in low or \"anything\" in low:\n",
    "            out.append(\"Engage/Ask questions\")\n",
    "        elif \"attend\" in low or \"event\" in low or \"livestream\" in low or \"live stream\" in low:\n",
    "            out.append(\"Attend event / livestream\")\n",
    "        elif \"join\" in low or \"subscribe\" in low or \"follow\" in low or \"whitelist\" in low:\n",
    "            out.append(\"Join/Subscribe\")\n",
    "        elif \"buy\" in low or \"invest\" in low or \"donate\" in low or \"stake\" in low or \"swap\" in low:\n",
    "            out.append(\"Buy / invest / donate\")\n",
    "        elif \"share\" in low or \"repost\" in low or \"like\" in low:\n",
    "            out.append(\"Share / repost / like\")\n",
    "        elif (\n",
    "            \"visit\" in low\n",
    "            or \"read\" in low\n",
    "            or \"watch\" in low\n",
    "            or \"link\" in low\n",
    "            or \"website\" in low\n",
    "            or \"check\" in low\n",
    "            or \"view charts\" in low\n",
    "        ):\n",
    "            out.append(\"Visit external link / watch video\")\n",
    "        else:\n",
    "            out.append(\"Other CTA\")\n",
    "    seen = set()\n",
    "    result: List[str] = []\n",
    "    for v in out:\n",
    "        if v not in seen:\n",
    "            seen.add(v)\n",
    "            result.append(v)\n",
    "    return result\n",
    "\n",
    "\n",
    "def _norm_evidence_labels(raw: object) -> List[str]:\n",
    "    labels = tokenize_multi(raw)\n",
    "    out: List[str] = []\n",
    "    for lbl in labels:\n",
    "        base = lbl.strip()\n",
    "        if not base:\n",
    "            continue\n",
    "        low = base.lower()\n",
    "        if base in EVID_BUCKETS:\n",
    "            if base != \"Link/URL\":\n",
    "                out.append(base)\n",
    "            continue\n",
    "        if \"link/url\" in low or \"link\" in low or \"url\" in low:\n",
    "            continue\n",
    "        elif \"statistic\" in low:\n",
    "            out.append(\"Statistics\")\n",
    "        elif \"quote\" in low or \"testimony\" in low:\n",
    "            out.append(\"Quotes/Testimony\")\n",
    "        elif \"chart\" in low or \"graph\" in low or \"diagram\" in low:\n",
    "            out.append(\"Chart / price graph / TA diagram\")\n",
    "        elif \"none / assertion only\" in low or \"assertion only\" in low:\n",
    "            out.append(\"None / assertion only\")\n",
    "        else:\n",
    "            out.append(\"Other (Evidence)\")\n",
    "    seen = set()\n",
    "    result: List[str] = []\n",
    "    for v in out:\n",
    "        if v not in seen:\n",
    "            seen.add(v)\n",
    "            result.append(v)\n",
    "    return result\n",
    "\n",
    "\n",
    "def build_style_tokens_no_theme(row: pd.Series) -> List[str]:\n",
    "    tokens: List[str] = []\n",
    "    for label in _norm_claim_labels(row.get(\"claim_types\")):\n",
    "        tokens.append(f\"claim={label}\")\n",
    "    for label in _norm_cta_labels(row.get(\"ctas\")):\n",
    "        tokens.append(f\"cta={label}\")\n",
    "    for label in _norm_evidence_labels(row.get(\"evidence\")):\n",
    "        tokens.append(f\"evid={label}\")\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb9c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_calibration_error(y_true, y_proba, n_bins=10) -> float:\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_proba = np.asarray(y_proba)\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    idx = np.digitize(y_proba, bins) - 1\n",
    "    ece = 0.0\n",
    "    n = len(y_true)\n",
    "    for b in range(n_bins):\n",
    "        mask = idx == b\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        p_bin = float(y_proba[mask].mean())\n",
    "        y_bin = float(y_true[mask].mean())\n",
    "        weight = float(mask.sum() / n)\n",
    "        ece += weight * abs(p_bin - y_bin)\n",
    "    return float(ece)\n",
    "\n",
    "\n",
    "def sweep_thresholds(y_true, proba, grid=None):\n",
    "    grid = grid or [round(t, 2) for t in np.linspace(0.05, 0.95, 19)]\n",
    "    best = None\n",
    "    for t in grid:\n",
    "        pred = (proba >= t).astype(int)\n",
    "        macro_f1 = f1_score(y_true, pred, average=\"macro\")\n",
    "        if best is None or macro_f1 > best[\"macro_f1\"]:\n",
    "            best = {\"threshold\": float(t), \"macro_f1\": float(macro_f1)}\n",
    "    return best\n",
    "\n",
    "\n",
    "def fit_val_tuned_logreg(X_train, y_train, X_val, y_val, X_test, y_test, *, seed=0):\n",
    "    clf = LogisticRegression(\n",
    "        penalty=\"l2\",\n",
    "        C=1.0,\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=1000,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=seed,\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    val_proba = clf.predict_proba(X_val)[:, 1]\n",
    "    thr = sweep_thresholds(y_val, val_proba)\n",
    "\n",
    "    # retrain on train+val for test predictions\n",
    "    X_trainval = np.vstack([X_train, X_val])\n",
    "    y_trainval = np.concatenate([y_train, y_val])\n",
    "    clf2 = LogisticRegression(\n",
    "        penalty=\"l2\",\n",
    "        C=1.0,\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=1000,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=seed,\n",
    "    )\n",
    "    clf2.fit(X_trainval, y_trainval)\n",
    "    test_proba = clf2.predict_proba(X_test)[:, 1]\n",
    "    test_pred = (test_proba >= thr[\"threshold\"]).astype(int)\n",
    "\n",
    "    out = {\n",
    "        \"threshold\": float(thr[\"threshold\"]),\n",
    "        \"macro_f1\": float(f1_score(y_test, test_pred, average=\"macro\")),\n",
    "        \"macro_recall\": float(recall_score(y_test, test_pred, average=\"macro\")),\n",
    "        \"roc_auc\": float(roc_auc_score(y_test, test_proba)),\n",
    "        \"accuracy\": float(accuracy_score(y_test, test_pred)),\n",
    "        \"brier\": float(brier_score_loss(y_test, test_proba)),\n",
    "        \"ece\": float(expected_calibration_error(y_test, test_proba, n_bins=10)),\n",
    "        \"test_proba\": test_proba,\n",
    "        \"val_proba\": val_proba,\n",
    "    }\n",
    "    return out\n",
    "\n",
    "\n",
    "def fit_val_tuned_text(train_df, val_df, test_df, *, seed=0):\n",
    "    vec = TfidfVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        max_features=20000,\n",
    "        min_df=2,\n",
    "        strip_accents=\"unicode\",\n",
    "    )\n",
    "    X_train = vec.fit_transform(train_df[\"message\"].astype(str))\n",
    "    X_val = vec.transform(val_df[\"message\"].astype(str))\n",
    "    X_test = vec.transform(test_df[\"message\"].astype(str))\n",
    "\n",
    "    # Use saga for sparse high-dimensional LR.\n",
    "    clf = LogisticRegression(\n",
    "        penalty=\"l2\",\n",
    "        C=1.0,\n",
    "        solver=\"saga\",\n",
    "        max_iter=2000,\n",
    "        n_jobs=-1,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=seed,\n",
    "    )\n",
    "    clf.fit(X_train, train_df[\"y\"].astype(int).to_numpy())\n",
    "    val_proba = clf.predict_proba(X_val)[:, 1]\n",
    "    thr = sweep_thresholds(val_df[\"y\"].astype(int).to_numpy(), val_proba)\n",
    "\n",
    "    # retrain on train+val (keep sparse to avoid huge densification)\n",
    "    from scipy import sparse as _sp\n",
    "    X_trainval_sp = _sp.vstack([X_train, X_val])\n",
    "    y_trainval = np.concatenate([\n",
    "        train_df[\"y\"].astype(int).to_numpy(),\n",
    "        val_df[\"y\"].astype(int).to_numpy(),\n",
    "    ])\n",
    "    clf2 = LogisticRegression(\n",
    "        penalty=\"l2\",\n",
    "        C=1.0,\n",
    "        solver=\"saga\",\n",
    "        max_iter=2000,\n",
    "        n_jobs=-1,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=seed,\n",
    "    )\n",
    "    clf2.fit(X_trainval_sp, y_trainval)\n",
    "    test_proba = clf2.predict_proba(X_test)[:, 1]\n",
    "    test_pred = (test_proba >= thr[\"threshold\"]).astype(int)\n",
    "\n",
    "    y_test = test_df[\"y\"].astype(int).to_numpy()\n",
    "    out = {\n",
    "        \"threshold\": float(thr[\"threshold\"]),\n",
    "        \"macro_f1\": float(f1_score(y_test, test_pred, average=\"macro\")),\n",
    "        \"macro_recall\": float(recall_score(y_test, test_pred, average=\"macro\")),\n",
    "        \"roc_auc\": float(roc_auc_score(y_test, test_proba)),\n",
    "        \"accuracy\": float(accuracy_score(y_test, test_pred)),\n",
    "        \"brier\": float(brier_score_loss(y_test, test_proba)),\n",
    "        \"ece\": float(expected_calibration_error(y_test, test_proba, n_bins=10)),\n",
    "        \"test_proba\": test_proba,\n",
    "        \"val_proba\": val_proba,\n",
    "    }\n",
    "    return out\n",
    "\n",
    "\n",
    "def fit_val_tuned_style_no_theme(train_df, val_df, test_df, *, seed=0):\n",
    "    train_tokens = train_df.apply(build_style_tokens_no_theme, axis=1).tolist()\n",
    "    val_tokens = val_df.apply(build_style_tokens_no_theme, axis=1).tolist()\n",
    "    test_tokens = test_df.apply(build_style_tokens_no_theme, axis=1).tolist()\n",
    "\n",
    "    vocab = sorted(set(t for toks in (train_tokens + val_tokens) for t in toks))\n",
    "    mlb = MultiLabelBinarizer(classes=vocab)\n",
    "    X_train = mlb.fit_transform(train_tokens).astype(np.float32)\n",
    "    X_val = mlb.transform(val_tokens).astype(np.float32)\n",
    "    X_test = mlb.transform(test_tokens).astype(np.float32)\n",
    "\n",
    "    y_train = train_df[\"y\"].astype(int).to_numpy()\n",
    "    y_val = val_df[\"y\"].astype(int).to_numpy()\n",
    "    y_test = test_df[\"y\"].astype(int).to_numpy()\n",
    "\n",
    "    out = fit_val_tuned_logreg(X_train, y_train, X_val, y_val, X_test, y_test, seed=seed)\n",
    "    out[\"n_features\"] = int(len(vocab))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8324d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run leave-one-theme-out\n",
    "\n",
    "themes = [t for t in THEME_BUCKETS if t in set(df[\"theme_norm\"].unique())]\n",
    "\n",
    "rows = []\n",
    "for theme in themes:\n",
    "    test_df = df[df[\"theme_norm\"] == theme].copy()\n",
    "    trainval_df = df[df[\"theme_norm\"] != theme].copy()\n",
    "\n",
    "    # Enforce domain-disjointness: remove any domains that appear in the held-out theme.\n",
    "    test_domains = set(test_df[\"normalized_domain\"].astype(str).unique())\n",
    "    trainval_df = trainval_df[~trainval_df[\"normalized_domain\"].astype(str).isin(test_domains)].copy()\n",
    "\n",
    "    # Require both classes present in test.\n",
    "    if test_df[\"y\"].nunique() < 2:\n",
    "        print({\"theme\": theme, \"skipped\": \"test_has_single_class\", \"n_test\": int(len(test_df))})\n",
    "        continue\n",
    "    if trainval_df[\"y\"].nunique() < 2 or len(trainval_df) < 1000:\n",
    "        print({\"theme\": theme, \"skipped\": \"train_too_small_or_single_class\", \"n_trainval\": int(len(trainval_df))})\n",
    "        continue\n",
    "\n",
    "    train_df, val_df = train_test_split(\n",
    "        trainval_df,\n",
    "        test_size=0.125,\n",
    "        random_state=123,\n",
    "        stratify=trainval_df[\"y\"],\n",
    "    )\n",
    "\n",
    "    # Style-only (no Theme)\n",
    "    style = fit_val_tuned_style_no_theme(train_df, val_df, test_df, seed=0)\n",
    "    rows.append(\n",
    "        {\n",
    "            \"theme\": theme,\n",
    "            \"model\": \"style_only_no_theme\",\n",
    "            \"n_test\": int(len(test_df)),\n",
    "            \"pos_rate_test\": float(test_df[\"y\"].mean()),\n",
    "            **{k: style[k] for k in [\"macro_f1\", \"macro_recall\", \"roc_auc\", \"accuracy\", \"brier\", \"ece\", \"threshold\"]},\n",
    "            \"n_features\": int(style.get(\"n_features\", 0)),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # TF-IDF\n",
    "    text = fit_val_tuned_text(train_df, val_df, test_df, seed=0)\n",
    "    rows.append(\n",
    "        {\n",
    "            \"theme\": theme,\n",
    "            \"model\": \"tfidf\",\n",
    "            \"n_test\": int(len(test_df)),\n",
    "            \"pos_rate_test\": float(test_df[\"y\"].mean()),\n",
    "            **{k: text[k] for k in [\"macro_f1\", \"macro_recall\", \"roc_auc\", \"accuracy\", \"brier\", \"ece\", \"threshold\"]},\n",
    "            \"n_features\": np.nan,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Combined stacking (meta model trained on val)\n",
    "    meta_X_val = np.stack(\n",
    "        [\n",
    "            text[\"val_proba\"],\n",
    "            style[\"val_proba\"],\n",
    "            text[\"val_proba\"] * style[\"val_proba\"],\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    meta_X_test = np.stack(\n",
    "        [\n",
    "            text[\"test_proba\"],\n",
    "            style[\"test_proba\"],\n",
    "            text[\"test_proba\"] * style[\"test_proba\"],\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    meta = LogisticRegression(penalty=\"l2\", C=1.0, solver=\"lbfgs\", max_iter=1000)\n",
    "    meta.fit(meta_X_val, val_df[\"y\"].astype(int).to_numpy())\n",
    "    meta_val_proba = meta.predict_proba(meta_X_val)[:, 1]\n",
    "    thr = sweep_thresholds(val_df[\"y\"].astype(int).to_numpy(), meta_val_proba)\n",
    "\n",
    "    test_proba = meta.predict_proba(meta_X_test)[:, 1]\n",
    "    test_pred = (test_proba >= thr[\"threshold\"]).astype(int)\n",
    "    y_test = test_df[\"y\"].astype(int).to_numpy()\n",
    "    rows.append(\n",
    "        {\n",
    "            \"theme\": theme,\n",
    "            \"model\": \"combined\",\n",
    "            \"n_test\": int(len(test_df)),\n",
    "            \"pos_rate_test\": float(test_df[\"y\"].mean()),\n",
    "            \"macro_f1\": float(f1_score(y_test, test_pred, average=\"macro\")),\n",
    "            \"macro_recall\": float(recall_score(y_test, test_pred, average=\"macro\")),\n",
    "            \"roc_auc\": float(roc_auc_score(y_test, test_proba)),\n",
    "            \"accuracy\": float(accuracy_score(y_test, test_pred)),\n",
    "            \"brier\": float(brier_score_loss(y_test, test_proba)),\n",
    "            \"ece\": float(expected_calibration_error(y_test, test_proba, n_bins=10)),\n",
    "            \"threshold\": float(thr[\"threshold\"]),\n",
    "            \"n_features\": np.nan,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        {\n",
    "            \"theme\": theme,\n",
    "            \"n_test\": int(len(test_df)),\n",
    "            \"style_macro_f1\": round(style[\"macro_f1\"], 4),\n",
    "            \"tfidf_macro_f1\": round(text[\"macro_f1\"], 4),\n",
    "            \"combined_macro_f1\": round(rows[-1][\"macro_f1\"], 4),\n",
    "        }\n",
    "    )\n",
    "\n",
    "results = pd.DataFrame(rows)\n",
    "results_csv = RESULTS_DIR / \"leave_one_theme_out_results.csv\"\n",
    "results.to_csv(results_csv, index=False)\n",
    "print({\"results_csv\": str(results_csv)})\n",
    "display(results.sort_values([\"theme\", \"model\"]))\n",
    "\n",
    "\n",
    "# Plot macro-F1 by held-out theme\n",
    "plot_df = results.pivot(index=\"theme\", columns=\"model\", values=\"macro_f1\").reindex(themes)\n",
    "fig, ax = plt.subplots(figsize=(10.5, 3.2), dpi=300)\n",
    "x = np.arange(len(plot_df.index))\n",
    "width = 0.25\n",
    "\n",
    "series = [\n",
    "    (\"tfidf\", \"#666666\"),\n",
    "    (\"style_only_no_theme\", \"#1f77b4\"),\n",
    "    (\"combined\", \"#2ca02c\"),\n",
    "]\n",
    "\n",
    "for i, (col, color) in enumerate(series):\n",
    "    if col not in plot_df.columns:\n",
    "        continue\n",
    "    ax.bar(x + (i - 1) * width, plot_df[col].to_numpy(dtype=float), width, label=col, color=color)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(plot_df.index.tolist(), rotation=20, ha=\"right\")\n",
    "ax.set_ylabel(\"Macro-F1\")\n",
    "ax.set_title(\"Leave-one-theme-out generalization (test = held-out theme; domains removed from train)\")\n",
    "ax.set_ylim(0.0, 1.0)\n",
    "ax.grid(axis=\"y\", alpha=0.25)\n",
    "ax.legend(frameon=False, loc=\"lower left\")\n",
    "fig.tight_layout()\n",
    "\n",
    "fig_png = RESULTS_DIR / \"leave_one_theme_out_macro_f1.png\"\n",
    "fig_pdf = RESULTS_DIR / \"leave_one_theme_out_macro_f1.pdf\"\n",
    "fig.savefig(fig_png, dpi=300)\n",
    "fig.savefig(fig_pdf)\n",
    "plt.close(fig)\n",
    "print({\"macro_f1_plot_png\": str(fig_png)})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
